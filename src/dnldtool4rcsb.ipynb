{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DnldTool4RCSB: Download Tool for RCSB**\n",
        "\n",
        "This Jupyter Notebook downloads files (PDB and SDF) with atomic coordinates from the Protein Data Bank. It reads the HTML RCSB page to scrape data related to the identification of the active ligand. It focuses on structures for which binding affinity data is available. The active ligand is a small molecule bound to a protein target for which binding is available ([de Azevedo et al., 2024](https://doi.org/10.1002/jcc.27449)). It employs a requests library for downloading the atomic coordinates from the RCSB ([Veit-Acosta & de Azevedo, 2021](https://doi.org/10.2174/0929867328666210210121320)).\n",
        "<br> </br>\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1SpdLWV1K6Qtv0kvnRqdc3jc25mL0Vol_&export=view&authuser=0\" width=400 alt=\"DnldTool4RCSB Flowchart\">\n",
        "<br><i>Schematic flowchart for DnldTool4RCSB. It reads input files (lig.in, par.in, and pdb_codes.in) and downloads PDB and SDF from the Protein Data Bank for which binding affinity data (e.g., K<sub>i</sub>) is available. DnldTool4RCSB reads pdb_codes.in to define the PDB file to be downloaded from the Protein Data Bank. Input files lig.in and par.in define the folders used for downloading and the binding affinity. DnldTool4RCSB also downloads the SDF for the active ligand in the structure.</i></br>\n",
        "<br> </br>\n",
        "This code has the following functions\n",
        "\n",
        "**ISO80000**: This function determines the file size in kibibytes (KiB), mebibytes (MiB), gibibytes (GiB) etc. It employs ISO/IEC 80000 standard\n",
        "(https://www.iso.org/standard/87648.html).\n",
        "<br> </br>\n",
        "**read_dictionary**: This function reads a file with parameters stored as Python dictionaries.\n",
        "<br> </br>\n",
        "**read_pdb_codes**: This function reads a CSV file with PDB access codes and returns a list with them. It shows a summmary.\n",
        "<br> </br>\n",
        "**read_pdb_codes_no_summary**: This function reads a CSV file with PDB access codes and returns a list with them.\n",
        "<br> </br>\n",
        "**show_line**: This function shows a formatted line.\n",
        "<br> </br>\n",
        "**show_references**: This function shows references given as a list.\n",
        "<br> </br>\n",
        "**show_title**: This function shows a formatted line as a title.\n",
        "<br> </br>\n",
        "**rcsb_download_sdf**: This function downloads a specific ligand from the PDB using\n",
        "the RCSB Model Server API and saves it as an SD File.\n",
        "<br> </br>\n",
        "**scrape_data_rcsb**: This function scrapes data from the RCSB page. It saves it to a file with the identification of the active ligand found in a given structure.\n",
        "<br> </br>\n",
        "**extract_pdb_coordinates**: This function extracts coordinates from a downloaded\n",
        "PDB file. It intends to select target coordinates for docking simulations.\n",
        "<br> </br>\n",
        "**rcsb_download_pdb**: This function downloads a PDB file from the RCSB and saves it to a target directory.\n",
        "<br> </br>\n",
        "**zip_content_folders**: This function zips datasets folder in the content directory.\n",
        "<br> </br>\n",
        "**download_file_from_google_drive**: This function downloads a file from the google drive.\n",
        "<br> </br>\n",
        "**get_confirm_token**: This function gets the confirmation token.\n",
        "<br> </br>\n",
        "**save_response_content**: This function saves the response content.\n",
        "<br> </br>\n",
        "**unzip_a_folder**: This function unzips a previously zipped folder.\n",
        "<br> </br>\n",
        "**make_a_dir**: This function makes a directory in the content folder.\n",
        "<br> </br>\n",
        "<br> </br>\n",
        "Requests library docs available at https://requests.readthedocs.io/en/latest/.\n",
        "\n",
        "To install the requests library, type the following command.\n",
        "\n",
        "python -m pip install requests\n",
        "<br> </br>\n",
        "\n",
        "**References**\n",
        "<br> </br>\n",
        "de Azevedo WF Jr, Quiroga R, Villarreal MA, da Silveira NJF, Bitencourt-Ferreira\n",
        "G, da Silva AD, Veit-Acosta M, Oliveira PR, Tutone M, Biziukova N, Poroikov V, Tarasova O, Baud S. SAnDReS 2.0: Development of machine-learning models to explore the scoring function space. J Comput Chem. 2024;45(27):2333-2346.\n",
        "[doi:](https://doi.org/10.1002/jcc.27449)\n",
        "<br> </br>\n",
        "Veit-Acosta M, de Azevedo Júnior WF. The Impact of Crystallographic Data for the Development of Machine Learning Models to Predict Protein-Ligand Binding Affinity. Curr Med Chem. 2021;28(34):7006-7022.\n",
        "[doi:](https://doi.org/10.2174/0929867328666210210121320)"
      ],
      "metadata": {
        "id": "D8BY2Pv73j7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IlSB8UiQ40Ne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885aec37-b2f6-4d7a-e262-8a3e42c46098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/datasets' already exists.\n",
            "Directory '/content/datasets/Test' already exists.\n",
            "Directory '/content/misc' already exists.\n",
            "Directory '/content/misc/par' already exists.\n",
            "################################################################################\n",
            "# Downloading /misc/par/lig.in...done!                                         #\n",
            "################################################################################\n",
            "################################################################################\n",
            "# Downloading /misc/par/par.in...done!                                         #\n",
            "################################################################################\n",
            "################################################################################\n",
            "# Downloading /datasets/Test/pdb_codes.in...done!                              #\n",
            "################################################################################\n",
            "\n",
            "Reading PDBs from CSV file: ./datasets/Test/pdb_codes.in...done!\n",
            "\n",
            "############################### PDB Data Summary ###############################\n",
            "# Scraping data for structure 1E1X (1/38)...done!                              #\n",
            "# Scraping data for structure 1H1S (2/38)...done!                              #\n",
            "# Scraping data for structure 1OGU (3/38)...done!                              #\n",
            "# Scraping data for structure 1PXJ (4/38)...done!                              #\n",
            "# Scraping data for structure 1PXL (5/38)...done!                              #\n",
            "# Scraping data for structure 1PXM (6/38)...done!                              #\n",
            "# Scraping data for structure 1PXN (7/38)...done!                              #\n",
            "# Scraping data for structure 1PXO (8/38)...done!                              #\n",
            "# Scraping data for structure 1PXP (9/38)...done!                              #\n",
            "# Scraping data for structure 2A4L (10/38)...done!                             #\n",
            "# Scraping data for structure 2C5N (11/38)...done!                             #\n",
            "# Scraping data for structure 2C5O (12/38)...done!                             #\n",
            "# Scraping data for structure 2C5V (13/38)...done!                             #\n",
            "# Scraping data for structure 2C6O (14/38)...done!                             #\n",
            "# Scraping data for structure 2CLX (15/38)...done!                             #\n",
            "# Scraping data for structure 2FVD (16/38)...done!                             #\n",
            "# Scraping data for structure 2VU3 (17/38)...done!                             #\n",
            "# Scraping data for structure 2WEV (18/38)...done!                             #\n",
            "# Scraping data for structure 2XMY (19/38)...done!                             #\n",
            "# Scraping data for structure 3DDQ (20/38)...done!                             #\n",
            "# Scraping data for structure 3MY5 (21/38)...done!                             #\n",
            "# Scraping data for structure 3SW4 (22/38)...done!                             #\n",
            "# Scraping data for structure 3TNW (23/38)...done!                             #\n",
            "# Scraping data for structure 4BCK (24/38)...done!                             #\n",
            "# Scraping data for structure 4BCN (25/38)...done!                             #\n",
            "# Scraping data for structure 4BCO (26/38)...done!                             #\n",
            "# Scraping data for structure 4BCP (27/38)...done!                             #\n",
            "# Scraping data for structure 4BCQ (28/38)...done!                             #\n",
            "# Scraping data for structure 4EK8 (29/38)...done!                             #\n",
            "# Scraping data for structure 4FKL (30/38)...done!                             #\n",
            "# Scraping data for structure 4FKO (31/38)...done!                             #\n",
            "# Scraping data for structure 4NJ3 (32/38)...done!                             #\n",
            "# Scraping data for structure 5D1J (33/38)...done!                             #\n",
            "# Scraping data for structure 7KJS (34/38)...done!                             #\n",
            "# Scraping data for structure 8FP0 (35/38)...done!                             #\n",
            "# Scraping data for structure 4EOR (36/38)...done!                             #\n",
            "# Scraping data for structure 1PKD (37/38)...done!                             #\n",
            "# Scraping data for structure 1IEP (38/38)...done!                             #\n",
            "################################################################################\n",
            "\n",
            "############################# Ligand Data Summary ##############################\n",
            "# Ligand data written to a csv file: ligdata.csv.                              #\n",
            "# File size: 609.00 bytes (B) 609.00 bytes (B)                                 #\n",
            "################################################################################\n",
            "\n",
            "############################# PDB Download Summary #############################\n",
            "# The directory './datasets/Test/pdb/' exists.                                 #\n",
            "# Successfully downloaded to pdb1e1x.ent (1/38)                                #\n",
            "# Successfully downloaded to pdb1h1s.ent (2/38)                                #\n",
            "# Successfully downloaded to pdb1ogu.ent (3/38)                                #\n",
            "# Successfully downloaded to pdb1pxj.ent (4/38)                                #\n",
            "# Successfully downloaded to pdb1pxl.ent (5/38)                                #\n",
            "# Successfully downloaded to pdb1pxm.ent (6/38)                                #\n",
            "# Successfully downloaded to pdb1pxn.ent (7/38)                                #\n",
            "# Successfully downloaded to pdb1pxo.ent (8/38)                                #\n",
            "# Successfully downloaded to pdb1pxp.ent (9/38)                                #\n",
            "# Successfully downloaded to pdb2a4l.ent (10/38)                               #\n",
            "# Successfully downloaded to pdb2c5n.ent (11/38)                               #\n",
            "# Successfully downloaded to pdb2c5o.ent (12/38)                               #\n",
            "# Successfully downloaded to pdb2c5v.ent (13/38)                               #\n",
            "# Successfully downloaded to pdb2c6o.ent (14/38)                               #\n",
            "# Successfully downloaded to pdb2clx.ent (15/38)                               #\n",
            "# Successfully downloaded to pdb2fvd.ent (16/38)                               #\n",
            "# Successfully downloaded to pdb2vu3.ent (17/38)                               #\n",
            "# Successfully downloaded to pdb2wev.ent (18/38)                               #\n",
            "# Successfully downloaded to pdb2xmy.ent (19/38)                               #\n",
            "# Successfully downloaded to pdb3ddq.ent (20/38)                               #\n",
            "# Successfully downloaded to pdb3my5.ent (21/38)                               #\n",
            "# Successfully downloaded to pdb3sw4.ent (22/38)                               #\n",
            "# Successfully downloaded to pdb3tnw.ent (23/38)                               #\n",
            "# Successfully downloaded to pdb4bck.ent (24/38)                               #\n",
            "# Successfully downloaded to pdb4bcn.ent (25/38)                               #\n",
            "# Successfully downloaded to pdb4bco.ent (26/38)                               #\n",
            "# Successfully downloaded to pdb4bcp.ent (27/38)                               #\n",
            "# Successfully downloaded to pdb4bcq.ent (28/38)                               #\n",
            "# Successfully downloaded to pdb4ek8.ent (29/38)                               #\n",
            "# Successfully downloaded to pdb4fkl.ent (30/38)                               #\n",
            "# Successfully downloaded to pdb4fko.ent (31/38)                               #\n",
            "# Successfully downloaded to pdb4nj3.ent (32/38)                               #\n",
            "# Successfully downloaded to pdb5d1j.ent (33/38)                               #\n",
            "# Successfully downloaded to pdb7kjs.ent (34/38)                               #\n",
            "# Successfully downloaded to pdb8fp0.ent (35/38)                               #\n",
            "# Successfully downloaded to pdb4eor.ent (36/38)                               #\n",
            "# Successfully downloaded to pdb1pkd.ent (37/38)                               #\n",
            "# Successfully downloaded to pdb1iep.ent (38/38)                               #\n",
            "################################################################################\n",
            "\n",
            "Reading PDBs from CSV file: ./datasets/Test/pdb_codes.in...done!\n",
            "\n",
            "############################### PDB Data Summary ###############################\n",
            "# CSV file: ./datasets/Test/pdb_codes.in                                       #\n",
            "# Total number of PDB access codes: 38                                         #\n",
            "################################################################################\n",
            "\n",
            "################################## References ##################################\n",
            "# DOI: https://doi.org/DOI: https://doi.org/10.2174/0929867328666210210121320  #\n",
            "# DOI: https://doi.org/DOI: https://doi.org/10.1002/jcc.27449                  #\n",
            "################################################################################\n",
            "\n",
            "############################### PDB Data Summary ###############################\n",
            "# Selected coordinates written to 1E1X.pdb (1/38)                              #\n",
            "# Selected coordinates written to 1H1S.pdb (2/38)                              #\n",
            "# Selected coordinates written to 1OGU.pdb (3/38)                              #\n",
            "# Selected coordinates written to 1PXJ.pdb (4/38)                              #\n",
            "# Selected coordinates written to 1PXL.pdb (5/38)                              #\n",
            "# Selected coordinates written to 1PXM.pdb (6/38)                              #\n",
            "# Selected coordinates written to 1PXN.pdb (7/38)                              #\n",
            "# Selected coordinates written to 1PXO.pdb (8/38)                              #\n",
            "# Selected coordinates written to 1PXP.pdb (9/38)                              #\n",
            "# Selected coordinates written to 2A4L.pdb (10/38)                             #\n",
            "# Selected coordinates written to 2C5N.pdb (11/38)                             #\n",
            "# Selected coordinates written to 2C5O.pdb (12/38)                             #\n",
            "# Selected coordinates written to 2C5V.pdb (13/38)                             #\n",
            "# Selected coordinates written to 2C6O.pdb (14/38)                             #\n",
            "# Selected coordinates written to 2CLX.pdb (15/38)                             #\n",
            "# Selected coordinates written to 2FVD.pdb (16/38)                             #\n",
            "# Selected coordinates written to 2VU3.pdb (17/38)                             #\n",
            "# Selected coordinates written to 2WEV.pdb (18/38)                             #\n",
            "# Selected coordinates written to 2XMY.pdb (19/38)                             #\n",
            "# Selected coordinates written to 3DDQ.pdb (20/38)                             #\n",
            "# Selected coordinates written to 3MY5.pdb (21/38)                             #\n",
            "# Selected coordinates written to 3SW4.pdb (22/38)                             #\n",
            "# Selected coordinates written to 3TNW.pdb (23/38)                             #\n",
            "# Selected coordinates written to 4BCK.pdb (24/38)                             #\n",
            "# Selected coordinates written to 4BCN.pdb (25/38)                             #\n",
            "# Selected coordinates written to 4BCO.pdb (26/38)                             #\n",
            "# Selected coordinates written to 4BCP.pdb (27/38)                             #\n",
            "# Selected coordinates written to 4BCQ.pdb (28/38)                             #\n",
            "# Selected coordinates written to 4EK8.pdb (29/38)                             #\n",
            "# Selected coordinates written to 4FKL.pdb (30/38)                             #\n",
            "# Selected coordinates written to 4FKO.pdb (31/38)                             #\n",
            "# Selected coordinates written to 4NJ3.pdb (32/38)                             #\n",
            "# Selected coordinates written to 5D1J.pdb (33/38)                             #\n",
            "# Selected coordinates written to 7KJS.pdb (34/38)                             #\n",
            "# Selected coordinates written to 8FP0.pdb (35/38)                             #\n",
            "# Selected coordinates written to 4EOR.pdb (36/38)                             #\n",
            "# Selected coordinates written to 1PKD.pdb (37/38)                             #\n",
            "# Selected coordinates written to 1IEP.pdb (38/38)                             #\n",
            "################################################################################\n",
            "\n",
            "################################# SDF Summary ##################################\n",
            "# Successfully downloaded ligand to 1E1X_NW1.sdf (1/38)                        #\n",
            "# Successfully downloaded ligand to 1H1S_4SP.sdf (2/38)                        #\n",
            "# Successfully downloaded ligand to 1OGU_ST8.sdf (3/38)                        #\n",
            "# Successfully downloaded ligand to 1PXJ_CK2.sdf (4/38)                        #\n",
            "# Successfully downloaded ligand to 1PXL_CK4.sdf (5/38)                        #\n",
            "# Successfully downloaded ligand to 1PXM_CK5.sdf (6/38)                        #\n",
            "# Successfully downloaded ligand to 1PXN_CK6.sdf (7/38)                        #\n",
            "# Successfully downloaded ligand to 1PXO_CK7.sdf (8/38)                        #\n",
            "# Successfully downloaded ligand to 1PXP_CK8.sdf (9/38)                        #\n",
            "# Successfully downloaded ligand to 2A4L_RRC.sdf (10/38)                       #\n",
            "# Successfully downloaded ligand to 2C5N_CK8.sdf (11/38)                       #\n",
            "# Successfully downloaded ligand to 2C5O_CK2.sdf (12/38)                       #\n",
            "# Successfully downloaded ligand to 2C5V_CK4.sdf (13/38)                       #\n",
            "# Successfully downloaded ligand to 2C6O_4SP.sdf (14/38)                       #\n",
            "# Successfully downloaded ligand to 2CLX_F18.sdf (15/38)                       #\n",
            "# Successfully downloaded ligand to 2FVD_LIA.sdf (16/38)                       #\n",
            "# Successfully downloaded ligand to 2VU3_LZE.sdf (17/38)                       #\n",
            "# Successfully downloaded ligand to 2WEV_CK7.sdf (18/38)                       #\n",
            "# Successfully downloaded ligand to 2XMY_CDK.sdf (19/38)                       #\n",
            "# Successfully downloaded ligand to 3DDQ_RRC.sdf (20/38)                       #\n",
            "# Successfully downloaded ligand to 3MY5_RFZ.sdf (21/38)                       #\n",
            "# Successfully downloaded ligand to 3SW4_18K.sdf (22/38)                       #\n",
            "# Successfully downloaded ligand to 3TNW_F18.sdf (23/38)                       #\n",
            "# Successfully downloaded ligand to 4BCK_T3E.sdf (24/38)                       #\n",
            "# Successfully downloaded ligand to 4BCN_T9N.sdf (25/38)                       #\n",
            "# Successfully downloaded ligand to 4BCO_T6Q.sdf (26/38)                       #\n",
            "# Successfully downloaded ligand to 4BCP_T3C.sdf (27/38)                       #\n",
            "# Successfully downloaded ligand to 4BCQ_TJF.sdf (28/38)                       #\n",
            "# Successfully downloaded ligand to 4EK8_16K.sdf (29/38)                       #\n",
            "# Successfully downloaded ligand to 4FKL_CK2.sdf (30/38)                       #\n",
            "# Successfully downloaded ligand to 4FKO_20K.sdf (31/38)                       #\n",
            "# Successfully downloaded ligand to 4NJ3_2KD.sdf (32/38)                       #\n",
            "# Successfully downloaded ligand to 5D1J_56H.sdf (33/38)                       #\n",
            "# Successfully downloaded ligand to 7KJS_WG1.sdf (34/38)                       #\n",
            "# Successfully downloaded ligand to 8FP0_RRC.sdf (35/38)                       #\n",
            "# Successfully downloaded ligand to 4EOR_4SP.sdf (36/38)                       #\n",
            "# Successfully downloaded ligand to 1PKD_UCN.sdf (37/38)                       #\n",
            "# Successfully downloaded ligand to 1IEP_STI.sdf (38/38)                       #\n",
            "################################################################################\n",
            "updating: content/datasets/ (stored 0%)\n",
            "updating: content/datasets/Test/ (stored 0%)\n",
            "updating: content/datasets/Test/pdb/ (stored 0%)\n",
            "updating: content/datasets/Test/pdb/pdb1pxl.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/pdb3tnw.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/pdb1ogu.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/2C5O_CK2.sdf (deflated 71%)\n",
            "updating: content/datasets/Test/pdb/pdb4fkl.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2a4l.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4BCK_T3E.sdf (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/3TNW_F18.sdf (deflated 72%)\n",
            "updating: content/datasets/Test/pdb/1E1X_NW1.sdf (deflated 73%)\n",
            "updating: content/datasets/Test/pdb/7KJS_WG1.sdf (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4NJ3.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXO.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2wev.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4BCQ.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb4bck.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4BCK.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2FVD.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4FKO.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2C5V.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4EOR.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/3SW4.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb1h1s.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1PXM_CK5.sdf (deflated 73%)\n",
            "updating: content/datasets/Test/pdb/1PKD_UCN.sdf (deflated 77%)\n",
            "updating: content/datasets/Test/pdb/4BCO_T6Q.sdf (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/pdb3my5.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4EOR_4SP.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/8FP0.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2C5V_CK4.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/7KJS.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXM.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb1e1x.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4BCN.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXJ_CK2.sdf (deflated 72%)\n",
            "updating: content/datasets/Test/pdb/pdb4nj3.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4NJ3_2KD.sdf (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1PXJ.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4BCP_T3C.sdf (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/pdb4eor.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1OGU_ST8.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/3SW4_18K.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/pdb1pkd.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1H1S.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/3MY5_RFZ.sdf (deflated 73%)\n",
            "updating: content/datasets/Test/pdb/2CLX_F18.sdf (deflated 72%)\n",
            "updating: content/datasets/Test/pdb/pdb2c6o.ent (deflated 77%)\n",
            "updating: content/datasets/Test/pdb/pdb1pxo.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/2VU3.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXN_CK6.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/2C5O.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/3DDQ.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb3ddq.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4BCN_T9N.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2c5o.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1OGU.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2C5N.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb4fko.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2vu3.ent (deflated 77%)\n",
            "updating: content/datasets/Test/pdb/pdb4bcp.ent (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/2A4L_RRC.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2WEV.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb1pxj.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/2A4L.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXO_CK7.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/4FKL_CK2.sdf (deflated 71%)\n",
            "updating: content/datasets/Test/pdb/pdb2c5v.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1PXL.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb1pxn.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/2C5N_CK8.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/pdb4bcn.ent (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/2VU3_LZE.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/2C6O_4SP.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4FKL.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1H1S_4SP.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2CLX.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb8fp0.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PKD.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXP_CK8.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/pdb4bcq.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2XMY_CDK.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2FVD_LIA.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/2C6O.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb5d1j.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1IEP_STI.sdf (deflated 77%)\n",
            "updating: content/datasets/Test/pdb/pdb2xmy.ent (deflated 77%)\n",
            "updating: content/datasets/Test/pdb/1PXN.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb4bco.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1E1X.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4BCQ_TJF.sdf (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/pdb1iep.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4BCP.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb1pxm.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/2XMY.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/1PXP.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb4ek8.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/5D1J.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb7kjs.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/4EK8.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2c5n.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/2WEV_CK7.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/1IEP.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2clx.ent (deflated 77%)\n",
            "updating: content/datasets/Test/pdb/3TNW.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb2fvd.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/1PXL_CK4.sdf (deflated 74%)\n",
            "updating: content/datasets/Test/pdb/3MY5.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb3sw4.ent (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/4BCO.pdb (deflated 75%)\n",
            "updating: content/datasets/Test/pdb/pdb1pxp.ent (deflated 76%)\n",
            "updating: content/datasets/Test/pdb/3DDQ_RRC.sdf (deflated 75%)\n",
            "updating: content/datasets/Test/ligdata.csv (deflated 48%)\n",
            "updating: content/datasets/Test/pdb_codes.in (deflated 33%)\n",
            "  adding: content/datasets/Test/pdb/4FKO_20K.sdf (deflated 74%)\n",
            "  adding: content/datasets/Test/pdb/5D1J_56H.sdf (deflated 75%)\n",
            "  adding: content/datasets/Test/pdb/4EK8_16K.sdf (deflated 74%)\n",
            "  adding: content/datasets/Test/pdb/8FP0_RRC.sdf (deflated 78%)\n",
            "Folder zipped successfully to /content/datasets.zip\n",
            "updating: content/misc/ (stored 0%)\n",
            "updating: content/misc/par/ (stored 0%)\n",
            "updating: content/misc/par/lig.in (deflated 78%)\n",
            "updating: content/misc/par/par.in (deflated 60%)\n",
            "Folder zipped successfully to /content/misc.zip\n",
            "\n",
            "Contents of /content:\n",
            "total 11M\n",
            "drwxr-xr-x 3 root root 4.0K Jan 31 22:43 datasets\n",
            "-rw-r--r-- 1 root root  11M Jan 31 22:44 datasets.zip\n",
            "drwxr-xr-x 3 root root 4.0K Jan 31 22:43 misc\n",
            "-rw-r--r-- 1 root root 2.9K Jan 31 22:44 misc.zip\n",
            "drwxr-xr-x 1 root root 4.0K Jan 16 14:24 sample_data\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Jan 20 13:53:27 2026\n",
        "\n",
        "@author: walter\n",
        "\n",
        "DnldTool4RCSB: Download Tool for RCSB\n",
        "\n",
        "This Jupyter Notebook downloads files (PDB and SDF) with atomic coordinates from\n",
        "the Protein Data Bank. It reads the HTML RCSB page to scrape data related to the\n",
        "identification of the active ligand. It focuses on structures for which binding\n",
        "affinity data is available. The active ligand is a small molecule bound to a\n",
        "protein target for which binding is available (de Azevedo et al., 2024). It\n",
        "employs a requests library for downloading the atomic coordinates from the RCSB\n",
        "(Veit-Acosta & de Azevedo, 2021).\n",
        "\n",
        "This code has the following functions\n",
        "\n",
        "ISO80000: This function determines the file size in kibibytes (KiB), mebibytes\n",
        "(MiB), gibibytes (GiB) etc. It employs ISO/IEC 80000 standard\n",
        "(https://www.iso.org/standard/87648.html).\n",
        "\n",
        "read_dictionary: This function reads a file with parameters stored as Python\n",
        "dictionaries.\n",
        "\n",
        "read_pdb_codes: This function reads a CSV file with PDB access codes and returns\n",
        "a list with them. It shows a summmary.\n",
        "\n",
        "read_pdb_codes_no_summary: This function reads a CSV file with PDB access codes\n",
        "and returns a list with them.\n",
        "\n",
        "show_line: This function shows a formatted line.\n",
        "\n",
        "show_references: This function shows references given as a list.\n",
        "\n",
        "show_title: This function shows a formatted line as a title.\n",
        "\n",
        "rcsb_download_sdf: This function downloads a specific ligand from the PDB using\n",
        "the RCSB Model Server API and saves it as an SD File.\n",
        "\n",
        "scrape_data_rcsb: This function scrapes data from the RCSB page. It saves it to\n",
        "a file with the identification of the active ligand found in a given structure.\n",
        "\n",
        "extract_pdb_coordinates: This function extracts coordinates from a downloaded\n",
        "PDB file. It intends to select target coordinates for docking simulations.\n",
        "\n",
        "rcsb_download_pdb: This function downloads a PDB file from the RCSB and saves it\n",
        "to a target directory.\n",
        "\n",
        "zip_content_folders: This function zips datasets folder in the content\n",
        "directory.\n",
        "\n",
        "download_file_from_google_drive: This function downloads a file from the google\n",
        "drive.\n",
        "\n",
        "get_confirm_token: This function gets the confirmation token.\n",
        "\n",
        "save_response_content: This function saves the response content.\n",
        "\n",
        "unzip_a_folder: This function unzips a previously zipped folder.\n",
        "\n",
        "make_a_dir: This function makes a directory in the content folder.\n",
        "\n",
        "\n",
        "Requests library docs available at https://requests.readthedocs.io/en/latest/.\n",
        "\n",
        "To install the requests library, type the following command.\n",
        "\n",
        "python -m pip install requests\n",
        "\n",
        "\n",
        "\n",
        "References\n",
        "\n",
        "de Azevedo WF Jr, Quiroga R, Villarreal MA, da Silveira NJF, Bitencourt-Ferreira\n",
        "G, da Silva AD, Veit-Acosta M, Oliveira PR, Tutone M, Biziukova N, Poroikov V,\n",
        "Tarasova O, Baud S. SAnDReS 2.0: Development of machine-learning models to\n",
        "explore the scoring function space. J Comput Chem. 2024;45(27):2333-2346.\n",
        "[doi:](https://doi.org/10.1002/jcc.27449)\n",
        "\n",
        "Veit-Acosta M, de Azevedo Júnior WF. The Impact of Crystallographic Data for the\n",
        "Development of Machine Learning Models to Predict Protein-Ligand Binding\n",
        "Affinity. Curr Med Chem. 2021;28(34):7006-7022.\n",
        "[doi:](https://doi.org/10.2174/0929867328666210210121320)\n",
        "\n",
        "\"\"\"\n",
        "################################################################################\n",
        "# Define variables for references related to this program                      #\n",
        "################################################################################\n",
        "doistr = \"DOI: https://doi.org/\"\n",
        "\n",
        "sandres2doi = \"10.1002/jcc.27449\"\n",
        "\n",
        "pdb1doi = \"10.2174/0929867328666210210121320\"\n",
        "\n",
        "################################################################################\n",
        "# Define ISO80000() function                                                   #\n",
        "################################################################################\n",
        "def ISO80000(file2measure):\n",
        "    \"\"\"\n",
        "    This function determines the file size in kibibytes (KiB),\n",
        "    mebibytes (MiB), gibibytes (GiB) etc. It employs ISO/IEC 80000 standard\n",
        "    (https://www.iso.org/standard/87648.html).\n",
        "    It defines quantities and units used in information science and information\n",
        "    technology and specifies names and symbols for these quantities and units.\n",
        "    It has a scope; normative references; names, definitions, and symbols;\n",
        "    and prefixes for binary multiples.\n",
        "\n",
        "    Value       IEC                   SI\n",
        "    1024\t      2**10\t    Ki\tkibi    10**3   k   kilo\n",
        "    1024**2\t    2**20\t    Mi\tmebi    10**6   M   mega\n",
        "    1024**3\t    2**30\t    Gi\tgibi    10**9   G   giga\n",
        "    1024**4\t    2**40\t    Ti\ttebi    10**12  T   tera\n",
        "    1024**5\t    2**50\t    Pi\tpebi    10**15  P   peta\n",
        "    1024**6\t    2**60\t    Ei\texbi    10**18  E   exa\n",
        "    1024**7\t    2**70\t    Zi\tzebi    10**21  Z   zetta\n",
        "    1024**8\t    2**80\t    Yi\tyobi    10**24  Y   yotta\n",
        "    1024**9\t    2**90\t    Ri\trobi    10**27  R   ronna\n",
        "    1024**10\t  2**100\t  Qi\tquebi   10**30  Q   quetta\n",
        "\n",
        "    IEC: International Electrotechnical Commission\n",
        "    SI: Système International d'Unités\n",
        "\n",
        "    Source:\n",
        "    https://en.wikipedia.org/wiki/Binary_prefix\n",
        "\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import os, warnings\n",
        "\n",
        "    # Ignore warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # Get file size\n",
        "    size = os.path.getsize(file2measure)\n",
        "\n",
        "    # Check size\n",
        "    if size >= 1024 and size < 1024**2:\n",
        "        size_SI = size/1000\n",
        "        size_IEC = size/1024\n",
        "        unit_SI = \"kilobytes (kB)\"\n",
        "        unit_IEC = \"kibibytes (KiB)\"\n",
        "    elif size >= 1024**2 and size < 1024**3:\n",
        "        size_SI = size/(1000**2)\n",
        "        size_IEC = size/(1024**2)\n",
        "        unit_SI = \"megabytes (MB)\"\n",
        "        unit_IEC = \"mebibytes (MiB)\"\n",
        "    elif size >= 1024**3 and size < 1024**4:\n",
        "        size_SI = size/(1000**3)\n",
        "        size_IEC = size/(1024**3)\n",
        "        unit_SI = \"gigabytes (GB)\"\n",
        "        unit_IEC = \"gibibytes (GiB)\"\n",
        "    elif size >= 1024**4 and size < 1024**5:\n",
        "        size_SI = size/(1000**4)\n",
        "        size_IEC = size/(1024**4)\n",
        "        unit_SI = \"terabytes (TB)\"\n",
        "        unit_IEC = \"tebibytes (TiB)\"\n",
        "    elif size >= 1024**5 and size < 1024**6:\n",
        "        size_SI = size/(1000**5)\n",
        "        size_IEC = size/(1024**5)\n",
        "        unit_SI = \"petabytes (PB)\"\n",
        "        unit_IEC = \"pebibytes (PiB)\"\n",
        "    elif size >= 1024**6 and size < 1024**7:\n",
        "        size_SI = size/(1000**6)\n",
        "        size_IEC = size/(1024**6)\n",
        "        unit_SI = \"exabytes (EB)\"\n",
        "        unit_IEC = \"exbibytes (EiB)\"\n",
        "    elif size >= 1024**7 and size < 1024**8:\n",
        "        size_SI = size/(1000**7)\n",
        "        size_IEC = size/(1024**7)\n",
        "        unit_SI = \"zettabytes (ZB)\"\n",
        "        unit_IEC = \"zebibytes (ZiB)\"\n",
        "    elif size >= 1024**8 and size < 1024**9:\n",
        "        size_SI = size/(1000**8)\n",
        "        size_IEC = size/(1024**8)\n",
        "        unit_SI = \"yottabytes (YB)\"\n",
        "        unit_IEC = \"yobibytes (YiB)\"\n",
        "    elif size >= 1024**9 and size < 1024**10:\n",
        "        size_SI = size/(1000**9)\n",
        "        size_IEC = size/(1024**9)\n",
        "        unit_SI = \"ronnabytes (RB)\"\n",
        "        unit_IEC = \"robibytes (RiB)\"\n",
        "    elif size >= 1024**10:\n",
        "        size_SI = size/(1000**10)\n",
        "        size_IEC = size/(1024**10)\n",
        "        unit_IEC = \"quettabytes (QB)\"\n",
        "        unit_IEC = \"quebibytes (QiB)\"\n",
        "    else:\n",
        "        size_IEC = size\n",
        "        size_SI = size\n",
        "        unit_SI = \"bytes (B)\"\n",
        "        unit_IEC = \"bytes (B)\"\n",
        "\n",
        "    # Return size_SI, size_IEC, unit_SI, unit_IEC\n",
        "    return size_SI, size_IEC, unit_SI, unit_IEC\n",
        "\n",
        "################################################################################\n",
        "# Define read_dictionary() function                                            #\n",
        "################################################################################\n",
        "# Define read_dictionary() function\n",
        "def read_dictionary(dict_file):\n",
        "    \"\"\"\n",
        "    This function reads a file with parameters stored as Python dictionaries.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import ast\n",
        "\n",
        "    # Open dictionary\n",
        "    with open(dict_file) as f:\n",
        "            data_in = f.read()\n",
        "\n",
        "    # Reconstructing the data_in as a dictionary\n",
        "    dict = ast.literal_eval(data_in)\n",
        "\n",
        "    # Return dict\n",
        "    return dict\n",
        "\n",
        "################################################################################\n",
        "# Define read_pdb_codes() function                                             #\n",
        "################################################################################\n",
        "def read_pdb_codes(pdbs_in):\n",
        "    \"\"\"\n",
        "    This function reads a CSV file with PDB access codes and returns a list\n",
        "    with them. It shows a summmary.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import csv, sys\n",
        "\n",
        "    # Show message\n",
        "    evo_msg = f\"\\nReading PDBs from CSV file: {pdbs_in}...\"\n",
        "    print(f\"{evo_msg}\",end=\"\")\n",
        "\n",
        "    # Read PDB access codes\n",
        "    # Try to read a csv file\n",
        "    try:\n",
        "        fo_csv_in = open(pdbs_in,\"r\")\n",
        "        csv_in = csv.reader(fo_csv_in)\n",
        "    except IOError:\n",
        "        err_msg = f\"\\nIOError! I can't find file {pdbs_in}\"\n",
        "        sys.exit(f\"{err_msg}\")\n",
        "\n",
        "    # Set up a string and a list\n",
        "    aux_pdb = \"\"\n",
        "    pdb_list = []\n",
        "\n",
        "    # Looping through csv_in\n",
        "    for list_in in csv_in:\n",
        "        str_in = str(list_in).replace(\" \",\"\").replace(\"'\",\"\").replace(\"[\",\"\").\\\n",
        "                                                            replace(\"]\",\"\")\n",
        "        # Looping through str_in\n",
        "        for char in str_in:\n",
        "            if char != \",\":\n",
        "                aux_pdb += char\n",
        "            else:\n",
        "                pdb_list.append(aux_pdb)\n",
        "                aux_pdb = \"\"\n",
        "\n",
        "    # Get last PDB access code\n",
        "    pdb_list.append(aux_pdb)\n",
        "\n",
        "    # Show message\n",
        "    print(\"done!\")\n",
        "\n",
        "    # Call show_title() function\n",
        "    show_title(31,\" PDB Data Summary \",31)\n",
        "\n",
        "    # Call show_line() function twice and show message\n",
        "    n_pdb = len(pdb_list)\n",
        "    show_line(f\"CSV file: {pdbs_in}\")\n",
        "    show_line(f\"Total number of PDB access codes: {n_pdb}\")\n",
        "    print(80*\"#\")\n",
        "\n",
        "    # References for PDB\n",
        "    # Define c_line_list\n",
        "    c_line_list = [doistr+pdb1doi,doistr+sandres2doi]\n",
        "\n",
        "    # Call show_references() function\n",
        "    show_references(c_line_list)\n",
        "\n",
        "    # Return pdb_list\n",
        "    return pdb_list\n",
        "\n",
        "################################################################################\n",
        "# Define read_pdb_codes_no_summary() function                                  #\n",
        "################################################################################\n",
        "def read_pdb_codes_no_summary(pdbs_in):\n",
        "    \"\"\"\n",
        "    This function reads a CSV file with PDB access codes and returns a list\n",
        "    with them.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import csv, sys\n",
        "\n",
        "    # Show message\n",
        "    evo_msg = f\"\\nReading PDBs from CSV file: {pdbs_in}...\"\n",
        "    print(f\"{evo_msg}\",end=\"\")\n",
        "\n",
        "    # Read PDB access codes\n",
        "    # Try to read a csv file\n",
        "    try:\n",
        "        fo_csv_in = open(pdbs_in,\"r\")\n",
        "        csv_in = csv.reader(fo_csv_in)\n",
        "    except IOError:\n",
        "        err_msg = f\"\\nIOError! I can't find file {pdbs_in}\"\n",
        "        sys.exit(f\"{err_msg}\")\n",
        "\n",
        "    # Set up a string and a list\n",
        "    aux_pdb = \"\"\n",
        "    pdb_list = []\n",
        "\n",
        "    # Looping through csv_in\n",
        "    for list_in in csv_in:\n",
        "        str_in = str(list_in).replace(\" \",\"\").replace(\"'\",\"\").replace(\"[\",\"\").\\\n",
        "                                                            replace(\"]\",\"\")\n",
        "        # Looping through str_in\n",
        "        for char in str_in:\n",
        "            if char != \",\":\n",
        "                aux_pdb += char\n",
        "            else:\n",
        "                pdb_list.append(aux_pdb)\n",
        "                aux_pdb = \"\"\n",
        "\n",
        "    # Get last PDB access code\n",
        "    pdb_list.append(aux_pdb)\n",
        "\n",
        "    # Show message\n",
        "    print(\"done!\")\n",
        "\n",
        "    # Return pdb_list\n",
        "    return pdb_list\n",
        "\n",
        "################################################################################\n",
        "# Define show_line() function                                                  #\n",
        "################################################################################\n",
        "def show_line(c_line):\n",
        "    \"\"\"\n",
        "    This function shows a formatted line.\n",
        "    \"\"\"\n",
        "    # Define auxiliary variables\n",
        "    s1 = \" \"\n",
        "    h1 = \"#\"\n",
        "\n",
        "    # Prepare and show line\n",
        "    n_line = len(c_line)\n",
        "    comp = f\"{(77 - n_line)*s1}{h1}\"\n",
        "    print(f\"{h1} {c_line}{comp}\")\n",
        "\n",
        "################################################################################\n",
        "# Define show_references()                                                     #\n",
        "################################################################################\n",
        "def show_references(c_line_list):\n",
        "    \"\"\"\n",
        "    This function shows references given as a list.\n",
        "    \"\"\"\n",
        "    # Call show_title() function\n",
        "    show_title(34,\" References \",34)\n",
        "\n",
        "    # Looping through c_line_list\n",
        "    for c_line in c_line_list:\n",
        "        # Add doistr to c_line\n",
        "        c_line = doistr+c_line\n",
        "\n",
        "        # Call show_line() function\n",
        "        show_line(f\"{c_line}\")\n",
        "    print(80*\"#\")\n",
        "\n",
        "################################################################################\n",
        "# Define show_title() function                                                 #\n",
        "################################################################################\n",
        "def show_title(n1,c_title,n2):\n",
        "    \"\"\"\n",
        "    This function shows a formatted line as a title.\n",
        "    \"\"\"\n",
        "    # Define auxiliary variable\n",
        "    h1 = \"#\"\n",
        "\n",
        "    # Prepare and show line\n",
        "    print(f\"\\n{n1*h1}{c_title}{n2*h1}\")\n",
        "\n",
        "################################################################################\n",
        "# Define rcsb_download_sdf() function                                          #\n",
        "################################################################################\n",
        "def rcsb_download_sdf():\n",
        "    \"\"\"\n",
        "    This function downloads a specific ligand from the PDB using the RCSB Model\n",
        "    Server API and saves it as an SD File.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import requests\n",
        "    import pandas as pd\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/par.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/par.in\")\n",
        "    miscellaneous = dict.get(\"miscellaneous\")\n",
        "    project_dir = miscellaneous[\"project_dir\"]\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/lig.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/lig.in\")\n",
        "    binfo = dict.get(\"binfo\")\n",
        "    ligand_datafile = binfo[\"ligand_datafile\"]\n",
        "\n",
        "    # Call show_title() function\n",
        "    show_title(33,\" SDF Summary \",34)\n",
        "\n",
        "    # Read the CSV file and get only specified columns\n",
        "    df = pd.read_csv(project_dir+ligand_datafile)\n",
        "    pdb_col = df[\"PDB\"]\n",
        "    lig_col = df[\"Ligand\"]\n",
        "    cha_col = df[\"Chain\"]\n",
        "    num_col = df[\"Number\"]\n",
        "\n",
        "    # Looping through pdb_col\n",
        "    n_sdf = len(lig_col)\n",
        "    for i,pdb_id in enumerate(pdb_col):\n",
        "        # Define parameters for downloading\n",
        "        asym_id = cha_col[i]\n",
        "        auth_seq_id = num_col[i]\n",
        "        curr_sdf = pdb_id+f\"_{lig_col[i]}.sdf\"\n",
        "        #output_sdf = project_dir+\"pdb/\"+pdb_id+f\"_{lig_col[i]}.sdf\"\n",
        "        output_sdf = project_dir+\"pdb/\"+curr_sdf\n",
        "        url = f\"https://models.rcsb.org/v1/{pdb_id}/ligand?auth_seq_id={auth_seq_id}&label_asym_id={asym_id}&encoding=sdf\"\n",
        "\n",
        "        # Download\n",
        "        response = requests.get(url, allow_redirects=True)\n",
        "\n",
        "        # Check response.status_code\n",
        "        if response.status_code == 200:\n",
        "            with open(output_sdf, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "            # Call show_line() function\n",
        "            c_line = f\"Successfully downloaded ligand to {curr_sdf} \"\n",
        "            c_line += f\"({i+1}/{n_sdf})\"\n",
        "            show_line(f\"{c_line}\")\n",
        "        else:\n",
        "            c_line = \"Failed to download ligand. \"\n",
        "            c_line += f\"Status code: {response.status_code}\"\n",
        "            show_line(f\"{c_line}\")\n",
        "            c_line=\"Check if the PDB ID, asym_id, and auth_seq_id are correct.\"\n",
        "            show_line(f\"{c_line}\")\n",
        "\n",
        "    # Show message\n",
        "    h1 = \"#\"\n",
        "    print(f\"{80*h1}\")\n",
        "\n",
        "################################################################################\n",
        "# Define scrape_data_rcsb() function                                           #\n",
        "################################################################################\n",
        "def scrape_data_rcsb():\n",
        "    \"\"\"\n",
        "    This function scrapes data from the RCSB page. It saves it to a file with\n",
        "    the identification of the active ligand found in a given structure.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import requests\n",
        "    from bs4 import BeautifulSoup\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/par.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/par.in\")\n",
        "    miscellaneous = dict.get(\"miscellaneous\")\n",
        "    project_dir = miscellaneous[\"project_dir\"] # Project directory\n",
        "    file4pdb_codes = project_dir+miscellaneous[\"file4pdb_codes\"]\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/lig.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/lig.in\")\n",
        "    binfo = dict.get(\"binfo\")\n",
        "    ligand_datafile = binfo[\"ligand_datafile\"]\n",
        "\n",
        "    # Call read_pdb_codes_no_summary() function\n",
        "    pdb_list =read_pdb_codes_no_summary(file4pdb_codes)\n",
        "\n",
        "    # Set up header for binding_data\n",
        "    binding_data = str(binfo[\"ligand_labels\"]).replace(\"[\",\"\").\\\n",
        "     replace(\"]\",\"\").replace(\" \",\"\").replace(\"\\\"\",\"\").replace(\"\\'\",\"\")+\"\\n\"\n",
        "\n",
        "    # Define auxiliary variables\n",
        "    s1 = \" \"\n",
        "    h1 = \"#\"\n",
        "\n",
        "    # Call show_title() function\n",
        "    show_title(31,\" PDB Data Summary \",31)\n",
        "\n",
        "    # Get the number of PDBs\n",
        "    n_pdb = len(pdb_list)\n",
        "\n",
        "    # Looping through pdb_list\n",
        "    for i,pdb in enumerate(pdb_list):\n",
        "        # Show message\n",
        "        c_line = f\"Scraping data for structure {pdb} ({i+1}/{n_pdb})...\"\n",
        "        n_line = len(c_line)\n",
        "        comp = f\"{(72 - n_line)*s1}{h1}\"\n",
        "        print(f\"{h1} {c_line}\",end=\"\")\n",
        "\n",
        "        # Connect to the target URL\n",
        "        url = 'https://www.rcsb.org/structure/'+str(pdb).strip().upper()\n",
        "        page = requests.get(url)\n",
        "        html_data = page.text\n",
        "\n",
        "        # Parse the HTML content\n",
        "        alternative_soup = BeautifulSoup(html_data, 'html.parser')\n",
        "\n",
        "        # Assign None to label_asym_id\n",
        "        label_asym_id = None\n",
        "\n",
        "        # Try to scrap rcsb\n",
        "        try:\n",
        "            # Get a string from page\n",
        "            results = alternative_soup.find_all(name=\"a\")\n",
        "            for line in results:\n",
        "                str_line = str(line)\n",
        "                if \"encoding=sdf&amp;filename=\" in str_line:\n",
        "                    i_sdf = str_line.index(\".sdf\")\n",
        "                    i_ref = str_line.index(\"encoding=sdf&amp;filename=\")\n",
        "                    l_str = len(\"encoding=sdf&amp;filename=\")\n",
        "                    sd_f = str_line[i_ref+l_str:i_sdf+4]\n",
        "                    i_chain1 = sd_f.index(\"_\")+1\n",
        "                    i_chain2 = sd_f[i_chain1:].index(\"_\")+i_chain1\n",
        "                    i_lig_end = sd_f.index(\".sdf\")\n",
        "                    i_lig_start = i_chain2 + 1\n",
        "                    lig_id = sd_f[i_lig_start:i_lig_end]\n",
        "                    i_number1 = str_line.index(\"ligand?auth_seq_id=\")\n",
        "                    i_number1 += len(\"ligand?auth_seq_id=\")\n",
        "                    i_number2 = str_line[i_number1:].index(\"&amp;\")+i_number1\n",
        "                    ligand_number = str_line[i_number1:i_number2]\n",
        "                    label_asym_id = sd_f[i_chain1:i_chain2]\n",
        "                    auth_seq_id = ligand_number\n",
        "                    break\n",
        "\n",
        "        except:\n",
        "            # Call show_line() function\n",
        "            c_line = f\"I can't find ligand data for structure {pdb}\"\n",
        "            show_line(f\"{c_line}\")\n",
        "\n",
        "            return\n",
        "\n",
        "        # Update line\n",
        "        binding_data += pdb+\",\"+lig_id+\",\"+label_asym_id\n",
        "        binding_data += \",\"+auth_seq_id+\"\\n\"\n",
        "        print(f\"done!{comp}\")\n",
        "    print(f\"{80*h1}\")\n",
        "\n",
        "    # Open a new file and write content\n",
        "    lig_file = project_dir+ligand_datafile\n",
        "    fo_lig = open(lig_file,\"w\")\n",
        "    fo_lig.write(binding_data)\n",
        "    fo_lig.close()\n",
        "\n",
        "    # Call ISO80000() function\n",
        "    size_SI,size_IEC,unit_SI,unit_IEC = ISO80000(lig_file)\n",
        "\n",
        "    # Call show_title() function\n",
        "    show_title(29,\" Ligand Data Summary \",30)\n",
        "\n",
        "    # Call show_line() function\n",
        "    c_line = \"Ligand data written to a \"\n",
        "    c_line += f\"csv file: {ligand_datafile}.\"\n",
        "    show_line(f\"{c_line}\")\n",
        "\n",
        "    # Call show_line() function\n",
        "    c_line = f\"File size: {size_IEC:.2f} \"\n",
        "    c_line += f\"{unit_IEC} {size_SI:.2f} {unit_SI}\"\n",
        "    show_line(f\"{c_line}\")\n",
        "\n",
        "    print(f\"{80*h1}\")\n",
        "\n",
        "################################################################################\n",
        "# Define extract_pdb_coordinates() function                                    #\n",
        "################################################################################\n",
        "def extract_pdb_coordinates(receptor_xyz_scheme):\n",
        "    \"\"\"\n",
        "    This function extracts coordinates from a downloaded PDB file. It intends to\n",
        "    select target coordinates for docking simulations.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import pandas as pd\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/par.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/par.in\")\n",
        "    miscellaneous = dict.get(\"miscellaneous\")\n",
        "    project_dir = miscellaneous[\"project_dir\"]\n",
        "    pdb_in = project_dir+miscellaneous[\"file4pdb_codes\"]\n",
        "    curr_dir = project_dir+\"pdb/\"\n",
        "\n",
        "    # Read a CSV file\n",
        "    df = pd.read_csv(project_dir+\"ligdata.csv\")\n",
        "\n",
        "    # Call read_pdb_codes() function\n",
        "    pdbs = read_pdb_codes(pdb_in)\n",
        "\n",
        "    # Call show_title() function\n",
        "    show_title(31,\" PDB Data Summary \",31)\n",
        "\n",
        "    # Loopings through pdbs\n",
        "    n_pdb = len(pdbs)\n",
        "    for i,pdb in enumerate(pdbs):\n",
        "        # Define list\n",
        "        receptor_out = []\n",
        "\n",
        "        # Try to open a pdb file\n",
        "        try:\n",
        "            curr_file = curr_dir+\"pdb\"+pdb.lower()+\".ent\"\n",
        "            fo_pdb = open(curr_file,\"r\")\n",
        "            pdb_lines = fo_pdb.readlines()\n",
        "            fo_pdb.close()\n",
        "\n",
        "        except IOError:\n",
        "            # Call show_line() function\n",
        "            c_line = f\"IOError! I can`t find {curr_file}\"\n",
        "            show_line(f\"{c_line}\")\n",
        "            return\n",
        "\n",
        "        # Select the scheme and write related content\n",
        "        if receptor_xyz_scheme.lower() == \"receptor\":\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+water\":\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] == \"HOH\":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+cofactor\":\n",
        "            # Get index\n",
        "            curr_i = df.index[df[\"PDB\"] == pdb].tolist()\n",
        "            lig_list = df[\"Ligand\"].tolist()\n",
        "            curr_lig = lig_list[curr_i[0]]\n",
        "\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] != \"HOH\"\\\n",
        "                    and str_line[17:20] != curr_lig:\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+cofactor+water\":\n",
        "            # Get index\n",
        "            curr_i = df.index[df[\"PDB\"] == pdb].tolist()\n",
        "            lig_list = df[\"Ligand\"].tolist()\n",
        "            curr_lig = lig_list[curr_i[0]]\n",
        "\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] != curr_lig:\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+active\":\n",
        "            # Get index\n",
        "            curr_i = df.index[df[\"PDB\"] == pdb].tolist()\n",
        "            lig_list = df[\"Ligand\"].tolist()\n",
        "            curr_lig = lig_list[curr_i[0]]\n",
        "\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] != \"HOH\"\\\n",
        "                    and str_line[17:20] == curr_lig:\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+active+water\":\n",
        "            # Get index\n",
        "            curr_i = df.index[df[\"PDB\"] == pdb].tolist()\n",
        "            lig_list = df[\"Ligand\"].tolist()\n",
        "            curr_lig = lig_list[curr_i[0]]\n",
        "\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] == curr_lig:\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] == \"HOH\":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+active+cofactor\":\n",
        "            # Get index\n",
        "            curr_i = df.index[df[\"PDB\"] == pdb].tolist()\n",
        "            lig_list = df[\"Ligand\"].tolist()\n",
        "            curr_lig = lig_list[curr_i[0]]\n",
        "\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:6] == \"HETATM\" and str_line[17:20] != \"HOH\":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        elif receptor_xyz_scheme.lower() == \"receptor+active+cofactor+water\":\n",
        "            # Get index\n",
        "            curr_i = df.index[df[\"PDB\"] == pdb].tolist()\n",
        "            lig_list = df[\"Ligand\"].tolist()\n",
        "            curr_lig = lig_list[curr_i[0]]\n",
        "\n",
        "            # Looping through pdb_lines\n",
        "            for line in pdb_lines:\n",
        "                str_line = str(line)\n",
        "                if str_line[:6] == \"ATOM  \" or str_line[:6] == \"HETATM\":\n",
        "                    receptor_out.append(line)\n",
        "                elif str_line[:3] == \"TER\" or str_line[:3] == \"END\":\n",
        "                    receptor_out.append(line)\n",
        "\n",
        "        # Write selected coordinates\n",
        "        curr_pdb = pdb.upper()+\".pdb\"\n",
        "        output_file = curr_dir+curr_pdb\n",
        "        fo_out = open(output_file,\"w\")\n",
        "        fo_out.writelines(receptor_out)\n",
        "        fo_out.close()\n",
        "\n",
        "        # Call show_line() function\n",
        "        c_line = f\"Selected coordinates written to {curr_pdb} \"\n",
        "        c_line += f\"({i+1}/{n_pdb})\"\n",
        "        show_line(f\"{c_line}\")\n",
        "\n",
        "    # Show message\n",
        "    h1 = \"#\"\n",
        "    print(f\"{80*h1}\")\n",
        "\n",
        "################################################################################\n",
        "# Define rcsb_pdb_download() function                                          #\n",
        "################################################################################\n",
        "def rcsb_download_pdb():\n",
        "    \"\"\"\n",
        "    This function downloads a PDB file from the RCSB and saves it to a target\n",
        "    directory.\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import requests\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/par.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/par.in\")\n",
        "    miscellaneous = dict.get(\"miscellaneous\")\n",
        "    target_dir = miscellaneous[\"project_dir\"]+\"pdb/\"\n",
        "\n",
        "    # Call read_dictionary(\"/content/misc/par/lig.in\") function\n",
        "    dict = read_dictionary(\"/content/misc/par/lig.in\")\n",
        "    binfo = dict.get(\"binfo\")\n",
        "    ligand_datafile = binfo[\"ligand_datafile\"]\n",
        "\n",
        "    # Call scrape_data_rcsb() function\n",
        "    scrape_data_rcsb()\n",
        "\n",
        "    # Call show_title() function\n",
        "    show_title(29,\" PDB Download Summary \",29)\n",
        "\n",
        "    # Check whether a directory exists\n",
        "    if os.path.isdir(target_dir):\n",
        "        # Call show_line() function\n",
        "        c_line = f\"The directory '{target_dir}' exists.\"\n",
        "        show_line(f\"{c_line}\")\n",
        "\n",
        "    else:\n",
        "        # Call show_line() function\n",
        "        c_line = f\"The directory '{target_dir}' does not exist or is a file.\"\n",
        "        show_line(f\"{c_line}\")\n",
        "\n",
        "        # Try to make PDB directory\n",
        "        try:\n",
        "            os.mkdir(target_dir)\n",
        "        except Exception as e:\n",
        "            # Call show_line() function\n",
        "            c_line = f\"An error occurred: {e}\"\n",
        "            show_line(f\"{c_line}\")\n",
        "\n",
        "    # Read the CSV file, loading only the specified columns\n",
        "    df = pd.read_csv(miscellaneous[\"project_dir\"]+ligand_datafile)\n",
        "    pdb_col = df[\"PDB\"]\n",
        "\n",
        "    # Looping through pdb_col\n",
        "    n_pdb = len(pdb_col)\n",
        "    h1 = \"#\"\n",
        "    for i,pdb_id in enumerate(pdb_col):\n",
        "        # Define url and output_path\n",
        "        url = f\"https://files.rcsb.org/download/{pdb_id}.pdb\"\n",
        "        #output_path = f\"{target_dir}{pdb_id}.pdb\"\n",
        "        curr_pdb = \"pdb\"+pdb_id.lower()+\".ent\"\n",
        "        output_path = target_dir+curr_pdb\n",
        "\n",
        "        # Download\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check response.status_code\n",
        "        if response.status_code == 200:\n",
        "            with open(output_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "                # Call show_line() function\n",
        "                c_line = f\"Successfully downloaded to {curr_pdb} \"\n",
        "                c_line += f\"({i+1}/{n_pdb})\"\n",
        "                show_line(f\"{c_line}\")\n",
        "\n",
        "        else:\n",
        "            # Call show_line() function\n",
        "            c_line = \"Failed to download structure: \"\n",
        "            c_line += f\" Status code {response.status_code}\"\n",
        "            show_line(f\"{c_line}\")\n",
        "\n",
        "    # Show message\n",
        "    h1 = \"#\"\n",
        "    print(f\"{80*h1}\")\n",
        "\n",
        "################################################################################\n",
        "# Define zip_content_folders() function                                        #\n",
        "################################################################################\n",
        "def zip_content_folders():\n",
        "  \"\"\"\n",
        "  This function zips datasets folder in the content directory.\n",
        "  \"\"\"\n",
        "  # Import section\n",
        "  import os\n",
        "\n",
        "  # Try to zip a folder\n",
        "  try:\n",
        "    !zip -r /content/datasets.zip /content/datasets\n",
        "    print('Folder zipped successfully to /content/datasets.zip')\n",
        "\n",
        "  except Exception as e:\n",
        "    # Call show_line() function\n",
        "    c_line = f\"An error occurred: {e}\"\n",
        "\n",
        "  # Try to zip a folder\n",
        "  try:\n",
        "    !zip -r /content/misc.zip /content/misc\n",
        "    print('Folder zipped successfully to /content/misc.zip')\n",
        "\n",
        "  except Exception as e:\n",
        "    # Call show_line() function\n",
        "    c_line = f\"An error occurred: {e}\"\n",
        "\n",
        "  # Optional: List the content of /content to show the zipped file\n",
        "  print('\\nContents of /content:')\n",
        "  !ls -lh /content\n",
        "\n",
        "################################################################################\n",
        "# Define download_file_from_google_drive() function                            #\n",
        "################################################################################\n",
        "def download_file_from_google_drive(file_id, destination):\n",
        "    \"\"\"\n",
        "    This function downloads a file from the google drive.\n",
        "\n",
        "    Usage example:\n",
        "    # https://drive.google.com/file/d/1nt_SoOYmm9uz8J8Bm7A4VKxe4woGXvpo/view?usp=drive_link\n",
        "    file_id = \"1nt_SoOYmm9uz8J8Bm7A4VKxe4woGXvpo\"\n",
        "    destination = \"/misc/par/lig.in\"\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "    \"\"\"\n",
        "    # Import section\n",
        "    import requests\n",
        "\n",
        "    # Define variables\n",
        "    s1 = \" \"\n",
        "    h1 = \"#\"\n",
        "\n",
        "    # Show message\n",
        "    print(f\"{80*h1}\")\n",
        "    c_line = f\"Downloading {destination}...\"\n",
        "    n_line = len(c_line)\n",
        "    comp = f\"{(72 - n_line)*s1}{h1}\"\n",
        "    print(f\"{h1} {c_line}\",end = \"\")\n",
        "\n",
        "    # Define url\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    # Download with requests\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params={'id': file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    # Check token\n",
        "    if token:\n",
        "        params = {'id': file_id, 'confirm': token}\n",
        "        response = session.get(URL, params=params, stream=True)\n",
        "\n",
        "    # Call save_response_content() function\n",
        "    destination = \"/content/\"+destination\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "    # Show message\n",
        "    print(f\"done!{comp}\")\n",
        "    print(f\"{80*h1}\")\n",
        "\n",
        "################################################################################\n",
        "# Define get_confirm_token() function                                          #\n",
        "################################################################################\n",
        "def get_confirm_token(response):\n",
        "  \"\"\"\n",
        "  This function gets the confirmation token.\n",
        "  \"\"\"\n",
        "  for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "  return None\n",
        "\n",
        "################################################################################\n",
        "# Define save_response_content() function                                      #\n",
        "################################################################################\n",
        "def save_response_content(response, destination):\n",
        "  \"\"\"\n",
        "  This function saves the response content.\n",
        "  \"\"\"\n",
        "  CHUNK_SIZE = 32768\n",
        "  with open(destination, \"wb\") as f:\n",
        "    for chunk in response.iter_content(CHUNK_SIZE):\n",
        "      if chunk: # filter out keep-alive new chunks\n",
        "        f.write(chunk)\n",
        "\n",
        "################################################################################\n",
        "# Define unzip_a_folder() function                                             #\n",
        "################################################################################\n",
        "def unzip_a_folder(destination_path):\n",
        "  \"\"\"\n",
        "  This function unzips a previously zipped folder.\n",
        "  \"\"\"\n",
        "  # Import section\n",
        "  import os\n",
        "\n",
        "  # Try to unzip a folder\n",
        "  try:\n",
        "    curr_dir = \"/content/\"+destination_path.replace(\".zip\",\"\")\n",
        "    !unzip \"/content/{destination_path}\" -d \"{curr_dir}\"\n",
        "    print(f'Folder unzipped successfully to {curr_dir}')\n",
        "\n",
        "    # Attempt to remove the file\n",
        "    file_path = \"/content/\"+destination_path\n",
        "    os.remove(file_path)\n",
        "    print(f\"File '{file_path}' deleted successfully.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    # Call show_line() function\n",
        "    c_line = f\"An error occurred: {e}\"\n",
        "    print(f\"{c_line}\")\n",
        "\n",
        "################################################################################\n",
        "# Define make_a_dir() function                                                 #\n",
        "################################################################################\n",
        "def make_a_dir(dir_path):\n",
        "  \"\"\"\n",
        "  This function makes a directory in the content folder.\n",
        "  \"\"\"\n",
        "  # Import section\n",
        "  import os\n",
        "\n",
        "  # Check if the directory already exists to prevent errors\n",
        "  if not os.path.exists(dir_path):\n",
        "    # Create the directory\n",
        "    os.makedirs(dir_path)\n",
        "    print(f\"Directory '{dir_path}' created.\")\n",
        "  else:\n",
        "    print(f\"Directory '{dir_path}' already exists.\")\n",
        "\n",
        "################################################################################\n",
        "# Define main() function                                                       #\n",
        "################################################################################\n",
        "def main():\n",
        "    # Import section\n",
        "    import os\n",
        "    # Define receptor_xyz_scheme\n",
        "    #receptor_xyz_scheme = \"receptor\"\n",
        "    #receptor_xyz_scheme = \"receptor+water\"\n",
        "    #receptor_xyz_scheme = \"receptor+cofactor\"\n",
        "    receptor_xyz_scheme = \"receptor+cofactor+water\"\n",
        "    #receptor_xyz_scheme = \"receptor+active\"\n",
        "    #receptor_xyz_scheme = \"receptor+active+water\"\n",
        "    #receptor_xyz_scheme = \"receptor+active+cofactor\"\n",
        "    #receptor_xyz_scheme = \"receptor+active+cofactor+water\"\n",
        "\n",
        "    # Call make_a_dir() function\n",
        "    make_a_dir(\"/content/datasets\")\n",
        "    make_a_dir(\"/content/datasets/Test\")\n",
        "    make_a_dir(\"/content/misc\")\n",
        "    make_a_dir(\"/content/misc/par\")\n",
        "\n",
        "    # Call download_file_from_google_drive() function\n",
        "    file_id = \"1nt_SoOYmm9uz8J8Bm7A4VKxe4woGXvpo\"\n",
        "    destination = \"/misc/par/lig.in\"\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "    # Call download_file_from_google_drive() function\n",
        "    file_id = \"1w14sifC2nrMZDInRKf6pqx3a2ihJL6dK\"\n",
        "    destination = \"/misc/par/par.in\"\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "    # Call download_file_from_google_drive() function\n",
        "    file_id = \"1haLRCndmq58KmKyWQLw8vsMnHimYih78\"\n",
        "    destination = \"/datasets/Test/pdb_codes.in\"\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "    # Call rcsb_download_pdb() function\n",
        "    rcsb_download_pdb()\n",
        "\n",
        "    # Call extract_pdb_coordinates()\n",
        "    extract_pdb_coordinates(receptor_xyz_scheme)\n",
        "\n",
        "    # Call rcsb_download_sdf() function\n",
        "    rcsb_download_sdf()\n",
        "\n",
        "    # Call zip_content_folders() function\n",
        "    zip_content_folders()\n",
        "\n",
        "# Call main() function\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xe6fEX-z46a9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}